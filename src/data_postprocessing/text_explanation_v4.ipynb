{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b78759aaee41531",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T14:39:33.650068Z",
     "start_time": "2025-05-21T14:39:33.638046Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Text classification model\n",
    "import torch.nn as nn\n",
    "\n",
    "class TextClassifierModel(nn.Module):\n",
    "    def __init__(self, input_dim=768):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define individual layers\n",
    "        self.fc1 = nn.Linear(input_dim, input_dim // 4)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(input_dim // 4, input_dim // 8)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(input_dim // 8, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through all layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "    def encode(self, x):\n",
    "        # Pass through layers up to the one before the classification layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.relu2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6046a4cd6db69a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EXPLANATION FUNCTIONS\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Manually add more stopwords\n",
    "#custom_stopwords = {\"\"}  # Add your words here\n",
    "#stop_words.update(custom_stopwords)  # Merge with default stopwords\n",
    "\n",
    "# Function to remove stopwords from a text\n",
    "def remove_stopwords(text):\n",
    "    words = text.split(\" \")\n",
    "    filtered_words = [\n",
    "        word.lower().strip(string.punctuation) for word in words \n",
    "        if word.lower().strip(string.punctuation) not in stop_words\n",
    "    ]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "# Load the model used for embedding\n",
    "model_mumin_id = 'paraphrase-mpnet-base-v2'\n",
    "model_mumin = SentenceTransformer(model_mumin_id)\n",
    "\n",
    "# Prediction function for LIME\n",
    "def predict_fn(texts):\n",
    "    embeddings = model_mumin.encode(texts, convert_to_numpy=True) # Convert text to embeddings\n",
    "    inputs = torch.tensor(embeddings, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs).numpy()\n",
    "    return np.hstack([1 - outputs, outputs])  # Convert to probability format\n",
    "\n",
    "# Explanation function\n",
    "def explain_text(classifier_model, classifier_model_weights, news_text, output_explanation_file = 'lime_explanation_of_text_news.html', num_features = 10, feature_selection=\"lasso_path\"):\n",
    "    \n",
    "    #load the model weights \n",
    "    classifier_model.load_state_dict(torch.load(classifier_model_weights))\n",
    "    classifier_model.eval()\n",
    "    \n",
    "    # Initialize LIME explainer\n",
    "    explainer = LimeTextExplainer(class_names=[\"Fake\", \"Real\"], feature_selection=feature_selection)\n",
    "\n",
    "    # Generate explanation\n",
    "    explanation = explainer.explain_instance(remove_stopwords(news_text), predict_fn, num_features=num_features)\n",
    "    \n",
    "    # Display results\n",
    "    explanation.show_in_notebook()\n",
    "    explanation.save_to_file(output_explanation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e49c1732009e9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# EXPLANATION EXECUTION STEPS\n",
    "\n",
    "# Load the model used for classification, the model weights after training, and set to evaluation mode\n",
    "model = TextClassifierModel()\n",
    "# set the folder and the file with the model weights\n",
    "DATA_FOLDER = Path('./trained_models/')\n",
    "nn_weights = DATA_FOLDER/'nn_weights_trained_on_claims-seed42.pt'\n",
    "model.load_state_dict(torch.load(nn_weights))\n",
    "model.eval()\n",
    "\n",
    "# Select news\n",
    "news_text = 'INSERT NEWS TEXT HERE'\n",
    "print('Text of the news: ', news_text)\n",
    "\n",
    "# Execute the explanation function\n",
    "explain_text(model, nn_weights, news_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f1af2d-155a-44b1-bf95-ee69baa74ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
